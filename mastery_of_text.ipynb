{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71f0ecb9-2004-4ec9-95e1-b144cb1f28c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1. Total Lines in URL: 99969 Lines\n",
      "\n",
      "Q2. Total Words in URL: 795227 Words\n",
      "\n",
      "Q3. Total Occurrences of Apostle/apostle in URL: 113 Total Instances\n",
      "     -> 47 Isolated Instances (e.g. apostle. or apostle, or apostle)\n",
      "     -> 66 Other Instances (e.g. apostles, apostleship, apostles')\n",
      "\n",
      "Q4. Most Common Word: `the`, with 64309 Instances\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "url = 'https://www.gutenberg.org/cache/epub/10/pg10.txt'\n",
    "\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    pg10 = response.read().decode(\"utf-8\")\n",
    "\n",
    "''' 1. How many lines does the string have? '''\n",
    "    \n",
    "lines = pg10.split(\"\\n\")\n",
    "totalLines = 0\n",
    "for line in lines:\n",
    "    totalLines = totalLines + 1\n",
    "        \n",
    "print (f\"Q1. Total Lines in URL: {totalLines} Lines\\n\")\n",
    "\n",
    "''' 2. How many words does the string have? '''\n",
    "\n",
    "smallText = pg10.lower()\n",
    "wordsCollect = []\n",
    "wordCurrent = \"\" \n",
    "\n",
    "for character in smallText:\n",
    "    if character.isalpha(): \n",
    "        wordCurrent += character \n",
    "    else: \n",
    "        if wordCurrent != \"\":\n",
    "            wordsCollect.append(wordCurrent)\n",
    "            wordCurrent = \"\" \n",
    "        if wordCurrent == \"\": \n",
    "            wordCurrent = \"\"\n",
    "\n",
    "# NOTE: I added this part even if it doesn't change much as my testing made this a problem for strings ending in alphabet characters\n",
    "if wordCurrent != \"\":\n",
    "    wordsCollect.append(wordCurrent)\n",
    "                \n",
    "totalWords = len(wordsCollect)\n",
    "        \n",
    "print (f\"Q2. Total Words in URL: {totalWords} Words\\n\")\n",
    "\n",
    "''' 3. How many times does the word \"apostle\", ignoring capitalization, appear in the string? '''\n",
    "   \n",
    "totalApostleAll = smallText.count(\"apostle\")\n",
    "totalApostleExtra = smallText.count(\"apostles\")\n",
    "totalApostleAlone = 0\n",
    "\n",
    "for word in wordsCollect:\n",
    "    if word == \"apostle\":\n",
    "        totalApostleAlone += 1\n",
    "    \n",
    "print(f\"Q3. Total Occurrences of Apostle/apostle in URL: {totalApostleAll} Total Instances\")\n",
    "print(f\"     -> {totalApostleAlone} Isolated Instances (e.g. apostle. or apostle, or apostle)\")\n",
    "print(f\"     -> {totalApostleExtra} Other Instances (e.g. apostles, apostleship, apostles')\\n\")\n",
    "\n",
    "''' 4. What is the most common word, ignoring capitalization, in the string? '''\n",
    "\n",
    "smallTextDict = {}\n",
    "commonText = \"\"\n",
    "totalCommon = 0\n",
    "\n",
    "for word in wordsCollect:\n",
    "    if word in smallTextDict:\n",
    "        smallTextDict[word] += 1 \n",
    "    else:\n",
    "        smallTextDict[word] = 1 \n",
    "\n",
    "for word in smallTextDict:\n",
    "    if smallTextDict[word] > totalCommon:\n",
    "        commonText = word\n",
    "        totalCommon = smallTextDict[word]\n",
    "\n",
    "print(f\"Q4. Most Common Word: `{commonText}`, with {totalCommon} Instances\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
